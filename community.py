from collections import defaultdict, deque
from itertools import combinations
from datetime import datetime
import re
from openai import OpenAI
import os
from dotenv import load_dotenv
import csv
import matplotlib.pyplot as plt
import networkx as nx
import sys

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

plt.rcParams['font.family'] = 'Hiragino Sans'


# === ãƒ­ã‚°ã‚’æ§‹é€ åŒ– ===
def parse_log(log_text):
    pattern = r"\[(.*?)\] \[(.*?)\] (.+)"
    logs = []
    for line in log_text.strip().split("\n"):
        m = re.match(pattern, line)
        if m:
            timestamp = datetime.strptime(m.group(1), "%Y-%m-%d %H:%M:%S")
            speaker = m.group(2)
            utterance = m.group(3)
            logs.append({"time": timestamp, "speaker": speaker, "utterance": utterance})
    return logs


# === GPTã§è©±é¡Œã®ä¸€è‡´ã‚’åˆ¤å®š ===
def is_same_topic(history_utterances, current_utterance):
    history_text = "\n".join([f"- {u}" for u in history_utterances])
    prompt = f"""ä»¥ä¸‹ã¯ã€ã‚ã‚‹ä¼šè©±ã®ãƒ­ã‚°ã®ä¸€éƒ¨ã§ã™ã€‚
ã“ã®æµã‚Œã®ä¸­ã§ã€æœ€å¾Œã®ç™ºè©±ãŒã€åŒã˜è©±é¡Œã®ç¶šãã‹ã©ã†ã‹ã€‘ã‚’Yes/Noã§åˆ¤å®šã—ã¦ãã ã•ã„ã€‚

ã€ã“ã‚Œã¾ã§ã®ä¼šè©±ã€‘
{history_text}

ã€æœ€å¾Œã®ç™ºè©±ã€‘
- {current_utterance}

ã“ã®ç™ºè©±ã¯ã€ä¸Šã®ä¼šè©±ã¨åŒã˜è©±é¡Œã®ç¶šãã§ã™ã‹ï¼Ÿ Yes ã‹ No ã§ç­”ãˆã¦ãã ã•ã„ã€‚
"""
    res = client.chat.completions.create(
        # model="gpt-4o",
        model="gpt-4.1",
        messages=[
            {"role": "system", "content": "ã‚ãªãŸã¯ä¼šè©±åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚è©±é¡Œã®å¤‰åŒ–ã«æ•æ„Ÿã§ã™ã€‚"},
            {"role": "user", "content": prompt}
        ],
        temperature=0.0
    )
    return "yes" in res.choices[0].message.content.strip().lower()


# === ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åˆ†å‰² ===
def split_sessions(logs):
    sessions = []

    if sys.argv[1] == "1":  # 5, 10, 15, 20, 25, 30
        ends = [5, 10, 15, 20, 25, 30]
    elif sys.argv[1] == "2":  # 5, 10, 15, 21, 26, 32
        ends = [5, 10, 15, 21, 26, 32]
    elif sys.argv[1] == "3":  # 5, 10, 16, 22, 29, 37
        ends = [5, 10, 16, 22, 29, 37]

    for i, end in enumerate(ends):
        # æœ€åˆã®2ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯ã€ãã®çµ‚ç«¯ã®ç™ºè©±æ•°ã‚’ãã®ã¾ã¾ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã«
        if i < 2:
            window = end
        else:
            # 2ã¤å‰ã®çµ‚ç«¯ã¨ã®å·®åˆ†ã‚’ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã«
            window = end - ends[i - 2]
        start = max(0, end - window)
        sessions.append(logs[start:end])
        # é…åˆ—ã‚’æ”¹è¡Œã§çµåˆã—ã¦print
        # print(f"\n--- ã‚»ãƒƒã‚·ãƒ§ãƒ³ {i + 1} ({start}ã€œ{end}) ---")
        # for log in logs[start:end]:
        #     print(f"{log['utterance']}")

    return sessions


# === GPTã«ä»²ã®è‰¯ã•ã‚’å°‹ã­ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ===
def get_gpt_friendship_scores(session_logs, participants):
    conversation = "\n".join([f"[{log['speaker']}] {log['utterance']}" for log in session_logs])

    pair = [f"- {a} Ã— {b}" for a, b in combinations(participants, 2)]
    pair_lines = "\n".join(pair)
    output_format = "\n".join([f"{a}-{b}:" for a, b in combinations(participants, 2)])
#     prompt = f"""
# ä»¥ä¸‹ã®ä¼šè©±ã‚’èª­ã¿ã€å‚åŠ è€…ãã‚Œãã‚Œã®ã€Œä»²ã®è‰¯ã•ï¼ˆè¦ªå¯†åº¦ï¼‰ã€ã‚’ -1.0 ã€œ 1.0 ã®é–“ã®å®Ÿæ•°ï¼ˆå°æ•°ç¬¬1ä½ã¾ã§ï¼‰ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
# -1.0 ã¯æ˜ç¢ºãªå¯¾ç«‹ã€0 ã¯ä¸­ç«‹ã€+1.0 ã¯éå¸¸ã«è¦ªã—ã„é–¢ä¿‚ã‚’è¡¨ã—ã¾ã™ã€‚
# è©•ä¾¡å¯¾è±¡ã¯ä»¥ä¸‹ã®ãƒšã‚¢ã§ã™ï¼š

# {pair_lines}

# ä¼šè©±ï¼š
# {conversation}

# å‡ºåŠ›å½¢å¼ï¼š
# {output_format}
# """
    prompt = f"""
ä»¥ä¸‹ã®ä¼šè©±ã‚’èª­ã¿ã€å‚åŠ è€…ãã‚Œãã‚Œã®ã€Œä»²ã®è‰¯ã•ï¼ˆè¦ªå¯†åº¦ï¼‰ã€ã‚’ -1.0 ã€œ +1.0 ã®é–“ã®**å®Ÿæ•°ï¼ˆå°æ•°ç¬¬1ä½ã¾ã§ï¼‰**ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
0.0 ã¯ç‰¹ã«è¦ªã—ã•ã‚‚å¯¾ç«‹ã‚‚æ„Ÿã˜ãªã„ã€Œä¸­ç«‹çš„ãªçŠ¶æ…‹ã€ã§ã™ã€‚
ãã“ã‹ã‚‰ -1.0ï¼ˆå¼·ã„å¯¾ç«‹ï¼‰ ã€œ +1.0ï¼ˆéå¸¸ã«è¦ªã—ã„ï¼‰ ã«å‘ã‘ã¦ã€ã©ã‚Œãã‚‰ã„é›¢ã‚Œã¦ã„ã‚‹ã‹ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

å…·ä½“ä¾‹ï¼š
-1.0 ä¾‹ï¼šçš®è‚‰ã€æ‰¹åˆ¤ã€ç„¡è¦–ã€ç›¸æ‰‹ã‚’ç„¡è¦–ã—ã¦è©±ã‚’é€²ã‚ã‚‹
+1.0 ä¾‹ï¼šå…±æ„Ÿã€è¤’ã‚ã‚‹ã€ç›¸æ‰‹ã«è©±é¡Œã‚’æŒ¯ã‚‹ã€ä¸€ç·’ã«è¡Œå‹•ã™ã‚‹

è©•ä¾¡å¯¾è±¡ã¯ä»¥ä¸‹ã®ãƒšã‚¢ã§ã™ï¼š
{pair_lines}

ä¼šè©±ï¼š
{conversation}

å‡ºåŠ›å½¢å¼ï¼š
{output_format}
"""
    res = client.chat.completions.create(
        # model="gpt-4o",
        model="gpt-4.1",
        messages=[
            {"role": "user", "content": prompt}
        ],
        temperature=0.0
    )
    return parse_scores_from_response(res.choices[0].message.content)


# === GPTã®è¿”ç­”ã‚’è¾æ›¸ã«å¤‰æ› ===
def parse_scores_from_response(response_text):
    scores = {}
    lines = response_text.strip().split("\n")
    for line in lines:
        if ":" in line:
            pair, score = line.split(":")
            a, b = [x.strip() for x in pair.split("-")]
            # æ•°å€¤éƒ¨åˆ†ã ã‘ã‚’æŠ½å‡ºï¼ˆ-1.0 ï½ 1.0 ã‚’æƒ³å®šï¼‰
            match = re.search(r"-?\d+(\.\d+)?", score)
            if match:
                scores[(a, b)] = float(match.group())
            else:
                print(f"âš ï¸ æ•°å€¤æŠ½å‡ºå¤±æ•—: {line.strip()}")
    return scores


# === ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã«ã‚¹ã‚³ã‚¢æ›´æ–°ï¼ˆæ™‚é–“æ¸›è¡°ä»˜ãEMAï¼‰ ===

def compute_all_relationship_scores(logs, decay_factor=1.5):
    sessions = split_sessions(logs)
    # print(f"\nğŸ“ ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {len(sessions)}")

    relationship_scores = defaultdict(float)
    interaction_history = defaultdict(lambda: deque(maxlen=3))  # å„ãƒšã‚¢ã®ç›´è¿‘3ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ†ã®ç™ºè©±æ•°

    for idx, session in enumerate(sessions, 1):
        print(f"\n--- ã‚»ãƒƒã‚·ãƒ§ãƒ³ {idx} ---")
        # for log in session:
        #     print(f"[{log['time'].strftime('%H:%M:%S')}] [{log['speaker']}] {log['utterance']}")

        participants = list(set(log["speaker"] for log in session))
        # print(f"ğŸ‘¥ å‚åŠ è€…: {participants}")

        if len(participants) < 2:
            print("âš ï¸ å‚åŠ è€…ãŒ1äººä»¥ä¸‹ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
            continue

        # å„è©±è€…ã®ãã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã®ç™ºè©±å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        session_utterance_counts = defaultdict(int)
        for log in session:
            session_utterance_counts[log["speaker"]] += 1
        # print(f"ğŸ—£ï¸ ç™ºè©±æ•°: {dict(session_utterance_counts)}")

        # GPTã‚¹ã‚³ã‚¢ã‚’å–å¾—
        gpt_scores = get_gpt_friendship_scores(session, participants)
        # print(f"ğŸ“ ã‚»ãƒƒã‚·ãƒ§ãƒ³ {idx} ã® GPTã‚¹ã‚³ã‚¢:")
        # for (a, b), s in gpt_scores.items():
        #     print(f"{a} - {b}: {s:.2f}")

        for (a, b), score in gpt_scores.items():
            key = tuple(sorted([a, b]))
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã§ã®ç™ºè©±å›æ•°ï¼ˆãƒšã‚¢ã®ã†ã¡å°‘ãªã„æ–¹ï¼‰
            session_utterance = min(session_utterance_counts[a], session_utterance_counts[b])
            past_utterances = interaction_history[key]  # éå»ã®ç™ºè©±æ•°ï¼ˆç›´è¿‘3ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ†ï¼‰
            total_past_utterance = sum(past_utterances)  # éå»ã®ç™ºè©±æ•°ã®åˆè¨ˆ

            x_t = score  # GPTã‚¹ã‚³ã‚¢ãã®ã¾ã¾ä½¿ã†

            if key not in relationship_scores:
                relationship_scores[key] = x_t  # åˆå›ã¯ä»£å…¥
                # print(f"ğŸ†• åˆæœŸã‚¹ã‚³ã‚¢: {key} = {x_t:.2f}")
            else:
                ratio = session_utterance / (session_utterance + total_past_utterance)  # ä»Šã¾ã§ã®ç™ºè©±æ•°ã«å¯¾ã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®ç™ºè©±æ•°ã®æ¯”ç‡
                alpha = max(0.01, min(1.0, decay_factor * ratio))  # decay_factorã‚’æ›ã‘ã¦æ™‚é–“æ¸›è¡°ã‚’è€ƒæ…®ã€‚ã—ã‹ã—ã€Î±ã¯0.01ä»¥ä¸Š1.0ä»¥ä¸‹ã«åˆ¶é™
                # print(f"ğŸ”¢ Î±è¨ˆç®— ({a}-{b}): minç™ºè©±æ•°={session_utterance}, éå»åˆè¨ˆ={total_past_utterance}, Î±={alpha:.2f}")
                prev = relationship_scores[key]
                updated = alpha * x_t + (1 - alpha) * prev
                relationship_scores[key] = updated
                # print(f"ğŸ” EMAæ›´æ–°: {key} = {alpha:.2f}Ã—{x_t:.2f} + {(1-alpha):.2f}Ã—{prev:.2f} â†’ {updated:.2f}")
            # ç›´è¿‘å±¥æ­´ã«è¿½åŠ ï¼ˆæœ€å¤§3ä»¶ï¼‰
            interaction_history[key].append(session_utterance)

        # print(f"ğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³ {idx} çµ‚äº†æ™‚ã®é–¢ä¿‚ã‚¹ã‚³ã‚¢ï¼ˆç´¯ç©ï¼‰:")
        for (a, b), score in relationship_scores.items():
            print(f"{a} - {b}: {score:.2f}")

    return relationship_scores


def compute_unified_scores_per_session(logs):
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã«ã€ãã“ã¾ã§ã®ç´¯ç©ä¼šè©±å±¥æ­´ã‚’GPTã«ä¸ãˆã¦é–¢ä¿‚æ€§ã‚’æ¨å®šã€‚
    å„æ™‚ç‚¹ã§ã®ã‚¹ã‚³ã‚¢è¾æ›¸ã‚’ãƒªã‚¹ãƒˆã¨ã—ã¦è¿”ã™ã€‚
    """
    sessions = split_sessions(logs)
    # print(f"\nğŸ“ ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {len(sessions)}")

    all_session_scores = []
    cumulative_logs = []
    for idx, session in enumerate(sessions, 1):
        cumulative_logs.extend(session)
        print(f"\n--- ã‚»ãƒƒã‚·ãƒ§ãƒ³ {idx}ï¼ˆç´¯ç©å±¥æ­´ã§GPTæ¨å®šï¼‰ ---")
        for log in cumulative_logs:
            print(f"[{log['time'].strftime('%H:%M:%S')}] [{log['speaker']}] {log['utterance']}")

        participants = set(log["speaker"] for log in cumulative_logs)

        gpt_scores = get_gpt_friendship_scores(cumulative_logs, participants)
        print(f"ğŸ“ ã‚»ãƒƒã‚·ãƒ§ãƒ³ {idx} ã® GPTã‚¹ã‚³ã‚¢:")

        for (a, b), s in gpt_scores.items():
            print(f"{a} - {b}: {s:.2f}")

        all_session_scores.append(gpt_scores)

    return all_session_scores


# === ãƒ¡ã‚¤ãƒ³å‡¦ç† ===
if __name__ == "__main__":
    USE_SESSION_BASED = True  # â† False ã«ã™ã‚‹ã¨ä¸€æ‹¬æ¨å®šã«åˆ‡ã‚Šæ›¿ã‚ã‚‹

    with open(f"logs/conversation{sys.argv[1]}.txt", "r", encoding="utf-8") as f:
        log_text = f.read()

    logs = parse_log(log_text)

    if USE_SESSION_BASED:
        scores = compute_all_relationship_scores(logs)
    else:
        session_scores_list = compute_unified_scores_per_session(logs)
        # æœ€çµ‚ã‚¹ã‚³ã‚¢ã ã‘CSV & ã‚°ãƒ©ãƒ•ã«ä½¿ã†
        scores = session_scores_list[-1] if session_scores_list else {}

    # === ãªã‘ã‚Œã°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ ===
    os.makedirs("output", exist_ok=True)

    # # === â‘  CSVã«ä¿å­˜ ===
    # with open("output/relationship_scores.csv", "w", newline="", encoding="utf-8") as f:
    #     writer = csv.writer(f)
    #     writer.writerow(["Person1", "Person2", "Score"])
    #     for (a, b), score in scores.items():
    #         a, b = sorted([a, b])
    #         writer.writerow([a, b, round(score, 2)])
    # # print("âœ… CSVä¿å­˜å®Œäº†: output/relationship_scores.csv")

    # # === â‘¡ NetworkXã§ã‚°ãƒ©ãƒ•æç”» ===
    # G = nx.Graph()
    # for (a, b), score in scores.items():
    #     a, b = sorted([a, b])
    #     G.add_edge(a, b, score=score)

    # # 1. ã¾ãšè¨ˆç®—ã ã‘ã™ã‚‹
    # preliminary_weights = {}
    # for u, v in G.edges():
    #     score = G[u][v]['score']
    #     scaled = (score + 1.0) / 2.0  # 0.0ï½1.0ã«å¤‰æ›
    #     preliminary_weights[(u, v)] = scaled ** 6 * 200

    # # 2. æœ€å¤§weightã‚’å–å¾—
    # max_weight = max(preliminary_weights.values())
    # min_weight = max_weight / 7
    # # print(f"ğŸ” æœ€å¤§weight: {max_weight:.2f}, æœ€å°weightè¨­å®š: {min_weight:.2f}")

    # # 3. æœ€å°å€¤ã‚’è€ƒæ…®ã—ã¦weightã‚’ã‚»ãƒƒãƒˆ
    # for (u, v), prelim in preliminary_weights.items():
    #     adjusted_weight = max(min_weight, prelim)
    #     G[u][v]['weight'] = adjusted_weight
    #     # print(f"ã‚¹ã‚³ã‚¢èª¿æ•´: {u} - {v}: prelim={prelim:.2f} â†’ weight={adjusted_weight:.2f}")

    # # é…ç½®è¨ˆç®—ï¼ˆã‚¹ã‚³ã‚¢ãŒå¼·ã„ã»ã©å¼•ãåˆã†ï¼‰
    # pos = nx.spring_layout(G, weight='weight', seed=42, iterations=500)

    # # ç·šã®å¤ªã•ï¼ˆè¦ªå¯†åº¦ã®å¼·ã•ã«å¿œã˜ã¦ï¼‰
    # edge_weights = [max(0.5, 5 * abs(G[u][v]['score'])) for u, v in G.edges()]

    # # ã‚¹ã‚³ã‚¢ãƒ©ãƒ™ãƒ«ï¼ˆÂ±1.0ï¼‰
    # edge_labels = {(u, v): f"{G[u][v]['score']:.1f}" for u, v in G.edges()}

    # # æ•µå¯¾é–¢ä¿‚ã¯èµ¤ã€è¦ªå¯†ãªé–¢ä¿‚ã¯é’ã€‚0ä»¥ä¸Šã¯é’ã€0æœªæº€ã¯èµ¤
    # edge_colors = ['red' if G[u][v]['score'] < 0 else 'skyblue' for u, v in G.edges()]

    # plt.figure(figsize=(6, 6))  # å›³ã®ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚’æ­£æ–¹å½¢ã‚µã‚¤ã‚ºã§ä½œã‚‹
    # nx.draw_networkx_nodes(G, pos, node_color="skyblue", node_size=1000)  # ãƒãƒ¼ãƒ‰ï¼ˆï¼äººï¼‰ã‚’ã€Œç©ºè‰²ã€ã§å¤§ãã‚ï¼ˆã‚µã‚¤ã‚º1000ï¼‰ã«æç”»ã™ã‚‹
    # nx.draw_networkx_edges(G, pos, width=edge_weights, edge_color=edge_colors)  # è¾ºï¼ˆï¼é–¢ä¿‚æ€§ï¼‰ã‚’é‡ã¿ã«å¿œã˜ãŸå¤ªã•ï¼ˆedge_weightsï¼‰ã§æç”»ã™ã‚‹
    # nx.draw_networkx_labels(G, pos, font_size=12, font_family="Hiragino Sans")  # å„ãƒãƒ¼ãƒ‰ã«äººã®åå‰ã‚’ãƒ©ãƒ™ãƒ«ã¨ã—ã¦è¡¨ç¤º
    # nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=10, font_family="Hiragino Sans")  # å„è¾ºã«ã€Œã‚¹ã‚³ã‚¢ã€ã‚’è¡¨ç¤ºï¼ˆå°æ•°ç‚¹1æ¡ã¾ã§ï¼‰

    # plt.title("é–¢ä¿‚æ€§ã‚°ãƒ©ãƒ•")
    # plt.axis("off")
    # plt.tight_layout()
    # plt.savefig("output/relationship_graph.png")
    # plt.close()
    # print("âœ… ã‚°ãƒ©ãƒ•ç”»åƒä¿å­˜å®Œäº†: output/relationship_graph.png")

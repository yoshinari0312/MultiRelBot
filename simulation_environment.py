"""
ä¼šè©±ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒ
äººé–“LLM 3å + ãƒ­ãƒœãƒƒãƒˆä»‹å…¥ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
"""

import networkx as nx
from typing import List, Dict, Tuple, Optional
from datetime import datetime
import random
import config
from human_llm_simulator import HumanLLMSimulator
from intervention_planner import InterventionPlanner
from community_analyzer import CommunityAnalyzer
from azure_clients import get_azure_chat_completion_client, build_chat_completion_params


class SimulationEnvironment:
    """ä¼šè©±ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒ"""

    def __init__(self):
        """åˆæœŸåŒ–"""
        self._CFG = config.get_config()

        # ãƒšãƒ«ã‚½ãƒŠè¨­å®š
        self.personas = ["A", "B", "C"]
        personas_cfg = getattr(self._CFG.env, "personas", {})
        self.persona_triggers = {
            name: info.get("triggers", []) if isinstance(info, dict) else []
            for name, info in personas_cfg.items()
        }

        # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
        sim_cfg = getattr(self._CFG, "simulation", None)
        self.max_human_utterances = getattr(sim_cfg, "max_human_utterances", 45)
        self.stability_check_interval = getattr(sim_cfg, "stability_check_interval", 3)
        self.consecutive_stable_threshold = getattr(
            sim_cfg, "consecutive_stable_threshold", 2
        )

        # è©•ä¾¡è¨­å®š
        self.evaluation_horizon = getattr(self._CFG.env, "evaluation_horizon", 3)

        # äººé–“LLMã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼
        self.human_llm = HumanLLMSimulator(self.personas, self.persona_triggers)

        # è©±é¡Œç”Ÿæˆç”¨ã®æ—¢ä½¿ç”¨åœ°é›·ãƒªã‚¹ãƒˆ
        self.used_triggers = []

    def generate_topic(self) -> Tuple[str, Optional[str]]:
        """
        è©±é¡Œã‚’ç”Ÿæˆ

        Returns:
            (topic, topic_trigger): è©±é¡Œã¨ãƒˆãƒªã‚¬ãƒ¼ã¨ãªã£ãŸåœ°é›·
        """
        # å…¨åœ°é›·ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«1ã¤é¸æŠï¼ˆæ—¢ã«ä½¿ç”¨ã—ãŸåœ°é›·ã¯é™¤å¤–ï¼‰
        all_triggers = set()
        for triggers in self.persona_triggers.values():
            all_triggers.update(triggers)

        available_triggers = list(all_triggers - set(self.used_triggers))

        if not available_triggers:
            # å…¨ã¦ä½¿ã„åˆ‡ã£ãŸã‚‰ãƒªã‚»ãƒƒãƒˆ
            self.used_triggers = []
            available_triggers = list(all_triggers)

        if not available_triggers:
            return "è‡ªç”±ãªè©±é¡Œ", None

        selected_trigger = random.choice(available_triggers)
        self.used_triggers.append(selected_trigger)

        # Azure OpenAI ã§è©±é¡Œç”Ÿæˆ
        client, deployment = get_azure_chat_completion_client(
            self._CFG.llm, model_type="topic"
        )
        if not client or not deployment:
            return f"{selected_trigger}ã«ã¤ã„ã¦", selected_trigger

        generation_prompt = f"""
ã‚ãªãŸã¯äººé–“3äººãŒè©±ã™ãŸã‚ã®ã€è©±é¡Œã‚’1ã¤ã ã‘ææ¡ˆã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

ä»¥ä¸‹ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«é–¢é€£ã™ã‚‹è©±é¡Œã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š
{selected_trigger}

ã“ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«ç›´æ¥çš„ã«é–¢é€£ã™ã‚‹å…·ä½“çš„ãªè©±é¡Œã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
ä¾‹ï¼š
- ã€ŒãŠé‡‘ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼ â†’ ã€Œæœ€è¿‘ã®ç‰©ä¾¡é«˜ã«ã¤ã„ã¦ã€ã€ŒæŠ•è³‡ã®å§‹ã‚æ–¹ã€
- ã€Œã‚²ãƒ¼ãƒ ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼ â†’ ã€Œæœ€æ–°ã®ã‚²ãƒ¼ãƒ ãƒˆãƒ¬ãƒ³ãƒ‰ã€ã€Œeã‚¹ãƒãƒ¼ãƒ„ã®å°†æ¥ã€
- ã€Œæ˜ ç”»ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼ â†’ ã€Œä»Šå¹´ã®ã‚¢ã‚«ãƒ‡ãƒŸãƒ¼è³ä½œå“ã€ã€Œå¥½ããªæ˜ ç”»ç›£ç£ã€

è©±é¡Œã‚’1ãƒ•ãƒ¬ãƒ¼ã‚ºï¼ˆ3-10èªï¼‰ã§1ã¤ã ã‘ææ¡ˆã—ã¦ãã ã•ã„ã€‚
"""

        messages = [{"role": "user", "content": generation_prompt}]
        params = build_chat_completion_params(
            deployment, messages, self._CFG.llm, temperature=0.9
        )

        try:
            res = client.chat.completions.create(**params)
            topic = res.choices[0].message.content.strip()
            return topic, selected_trigger
        except Exception as e:
            print(f"âš ï¸ è©±é¡Œç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return f"{selected_trigger}ã«ã¤ã„ã¦", selected_trigger

    def evaluate_relationships(self, logs: List[Dict]) -> Tuple[Dict, bool, bool]:
        """
        é–¢ä¿‚æ€§ã‚’è©•ä¾¡

        Args:
            logs: ä¼šè©±ãƒ­ã‚°

        Returns:
            (metrics, is_stable, has_isolated): é–¢ä¿‚æ€§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€å®‰å®šåˆ¤å®šã€ç–å¤–ãƒãƒ¼ãƒ‰æœ‰ç„¡
        """
        # CommunityAnalyzerã‚’ä½¿ç”¨ã—ã¦é–¢ä¿‚æ€§ã‚’è©•ä¾¡
        analyzer = CommunityAnalyzer()

        # ãƒ­ãƒœãƒƒãƒˆç™ºè©±ã‚’é™¤å¤–ã—ãŸä¼šè©±ãƒ­ã‚°ã‚’ä½œæˆ
        max_history_relation = getattr(self._CFG.env, "max_history_relation", 3) or 3
        human_logs = [log for log in logs if log.get("speaker") != "ãƒ­ãƒœãƒƒãƒˆ"]
        filtered_logs = human_logs[-max_history_relation:]

        if len(filtered_logs) < 3:
            # 3ç™ºè©±æœªæº€ã¯è©•ä¾¡ä¸å¯
            return {}, False, False

        # é–¢ä¿‚æ€§ã‚¹ã‚³ã‚¢ã‚’å–å¾—
        scores = analyzer.estimate_relation(filtered_logs)

        # ã‚°ãƒ©ãƒ•æ§‹ç¯‰
        graph = nx.Graph()
        for (a, b), score in scores.items():
            graph.add_edge(a, b, score=score)

        # ä¸‰è§’å½¢ã®ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        triangle_scores = analyzer.analyze_triangles(graph)

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—
        metrics = {"edges": scores, "unstable_triads": 0, "isolated_nodes": []}

        # ä¸å®‰å®šä¸‰è§’å½¢ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        for triangle, (struct, avg_score) in triangle_scores.items():
            if struct in ("---", "++-", "+-+", "-++"):
                metrics["unstable_triads"] += 1

        # ç–å¤–ãƒãƒ¼ãƒ‰ã‚’æ¤œå‡ºï¼ˆå…¨ã¦ã®ã‚¨ãƒƒã‚¸ãŒ0.0ä»¥ä¸‹ï¼‰
        for node in self.personas:
            edges = [
                (
                    scores.get((node, other), 0.0)
                    if node < other
                    else scores.get((other, node), 0.0)
                )
                for other in self.personas
                if other != node
            ]
            if all(edge <= 0.0 for edge in edges):
                metrics["isolated_nodes"].append(node)

        # å®‰å®šåˆ¤å®š: ä¸å®‰å®šä¸‰è§’å½¢æ•°ãŒ0 ã‹ã¤ ç–å¤–ãƒãƒ¼ãƒ‰ãŒå­˜åœ¨ã—ãªã„
        is_stable = (
            metrics["unstable_triads"] == 0 and len(metrics["isolated_nodes"]) == 0
        )
        has_isolated = len(metrics["isolated_nodes"]) > 0

        return metrics, is_stable, has_isolated

    def should_intervene(
        self, logs: List[Dict], metrics: Dict
    ) -> Tuple[bool, Optional[Dict], Optional[str]]:
        """
        ä»‹å…¥åˆ¤å®š

        Args:
            logs: ä¼šè©±ãƒ­ã‚°
            metrics: é–¢ä¿‚æ€§ãƒ¡ãƒˆãƒªã‚¯ã‚¹

        Returns:
            (should_intervene, plan, robot_utterance): ä»‹å…¥åˆ¤å®šã€ä»‹å…¥ãƒ—ãƒ©ãƒ³ã€ãƒ­ãƒœãƒƒãƒˆç™ºè©±
        """
        # ä¸å®‰å®šä¸‰è§’å½¢ã¾ãŸã¯ç–å¤–ãƒãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã«ä»‹å…¥
        unstable_triads = metrics.get("unstable_triads", 0)
        isolated_nodes = metrics.get("isolated_nodes", [])

        if unstable_triads == 0 and len(isolated_nodes) == 0:
            # å®‰å®šçŠ¶æ…‹ â†’ ä»‹å…¥ã—ãªã„
            return False, None, None

        # CommunityAnalyzer ã‚’ä½¿ç”¨ã—ã¦ã‚°ãƒ©ãƒ•ã¨ä¸‰è§’å½¢ã‚¹ã‚³ã‚¢ã‚’æ§‹ç¯‰
        analyzer = CommunityAnalyzer()
        human_logs = [log for log in logs if log.get("speaker") != "ãƒ­ãƒœãƒƒãƒˆ"]
        max_history_relation = getattr(self._CFG.env, "max_history_relation", 3) or 3
        filtered_logs = human_logs[-max_history_relation:]

        scores = analyzer.estimate_relation(filtered_logs)
        graph = nx.Graph()
        for (a, b), score in scores.items():
            graph.add_edge(a, b, score=score)

        triangle_scores = analyzer.analyze_triangles(graph)

        # InterventionPlannerã§ä»‹å…¥è¨ˆç”»
        planner = InterventionPlanner(
            graph=graph,
            triangle_scores=triangle_scores,
            isolation_threshold=0.0,
            mode="proposal",
        )

        # æœ€æ–°10ç™ºè©±ã‚’å–å¾—ï¼ˆãƒ­ãƒœãƒƒãƒˆç™ºè©±ã‚’å«ã‚€ï¼‰
        session_logs = logs[-10:]
        plan = planner.plan_intervention(session_logs)

        if plan is None:
            return False, None, None

        # ãƒ­ãƒœãƒƒãƒˆç™ºè©±ã‚’ç”Ÿæˆ
        robot_utterance = planner.generate_robot_utterance(plan, session_logs)

        return True, plan, robot_utterance

    def run_episode(self, episode_id: int) -> Dict:
        """
        1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ

        Args:
            episode_id: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ID

        Returns:
            ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ±è¨ˆ
        """
        print(f"\n{'='*80}")
        print(f"ğŸ“º ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ {episode_id}")
        print(f"{'='*80}")

        # è©±é¡Œç”Ÿæˆ
        topic, topic_trigger = self.generate_topic()
        print(f"ğŸ“Œ è©±é¡Œ: {topic}")
        if topic_trigger:
            print(f"   (ãƒˆãƒªã‚¬ãƒ¼: {topic_trigger})")

        # åˆæœŸåŒ–
        logs = []
        human_utterance_count = 0
        consecutive_stable_count = 0
        robot_utterances = []
        intervention_count = 0

        # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰é–‹å§‹æ™‚åˆ»
        start_time = datetime.now()

        while human_utterance_count < self.max_human_utterances:
            # äººé–“ç™ºè©±ã‚’1ã¤ç”Ÿæˆ
            human_replies = self.human_llm.generate_human_reply(
                logs, topic=topic, topic_trigger=topic_trigger, num_speakers=1
            )

            if not human_replies:
                print("âš ï¸ äººé–“ç™ºè©±ç”Ÿæˆå¤±æ•—")
                break

            logs.extend(human_replies)
            human_utterance_count += 1

            # ç™ºè©±ã‚’è¡¨ç¤º
            for reply in human_replies:
                print(f"  [{reply['speaker']}] {reply['utterance']}")

            # stability_check_interval ã”ã¨ã«é–¢ä¿‚æ€§è©•ä¾¡
            if human_utterance_count % self.stability_check_interval == 0:
                print(f"\nğŸ“Š é–¢ä¿‚æ€§è©•ä¾¡ ({human_utterance_count}ç™ºè©±æ™‚ç‚¹)")

                metrics, is_stable, has_isolated = self.evaluate_relationships(logs)

                print(f"  ä¸å®‰å®šä¸‰è§’å½¢æ•°: {metrics.get('unstable_triads', 0)}")
                print(f"  ç–å¤–ãƒãƒ¼ãƒ‰: {metrics.get('isolated_nodes', [])}")
                print(f"  å®‰å®šçŠ¶æ…‹: {'âœ… ã¯ã„' if is_stable else 'âŒ ã„ã„ãˆ'}")

                # ã‚¨ãƒƒã‚¸ã‚¹ã‚³ã‚¢ã‚’è¡¨ç¤º
                edges = metrics.get("edges", {})
                if edges:
                    print(f"  é–¢ä¿‚æ€§ã‚¹ã‚³ã‚¢:")
                    for (a, b), score in sorted(edges.items()):
                        print(f"    {a}-{b}: {score:+.2f}")

                if is_stable:
                    consecutive_stable_count += 1
                    print(
                        f"  é€£ç¶šå®‰å®šå›æ•°: {consecutive_stable_count}/{self.consecutive_stable_threshold}"
                    )

                    if consecutive_stable_count >= self.consecutive_stable_threshold:
                        print(
                            f"\nğŸ‰ {self.consecutive_stable_threshold}å›é€£ç¶šã§å®‰å®š â†’ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº†"
                        )
                        break
                else:
                    consecutive_stable_count = 0

                    # ä»‹å…¥åˆ¤å®š
                    should_intervene, plan, robot_utterance = self.should_intervene(
                        logs, metrics
                    )

                    if should_intervene and robot_utterance:
                        intervention_count += 1
                        print(f"\nğŸ¤– ãƒ­ãƒœãƒƒãƒˆä»‹å…¥ ({intervention_count}å›ç›®)")
                        print(f"  ä»‹å…¥ã‚¿ã‚¤ãƒ—: {plan.get('type', 'ä¸æ˜')}")
                        print(f"  ç™ºè©±: {robot_utterance}")

                        robot_entry = {
                            "speaker": "ãƒ­ãƒœãƒƒãƒˆ",
                            "utterance": robot_utterance,
                            "plan": plan,
                        }
                        logs.append(robot_entry)
                        robot_utterances.append(robot_entry)

                        # evaluation_horizon å›äººé–“ç™ºè©±ã‚’ç”Ÿæˆ
                        print(f"  (ä»‹å…¥å¾Œ {self.evaluation_horizon}ç™ºè©±ç”Ÿæˆä¸­...)")
                        for _ in range(self.evaluation_horizon):
                            eval_replies = self.human_llm.generate_human_reply(
                                logs,
                                topic=topic,
                                topic_trigger=topic_trigger,
                                num_speakers=1,
                            )
                            if eval_replies:
                                logs.extend(eval_replies)
                                human_utterance_count += 1
                                for reply in eval_replies:
                                    print(
                                        f"  [{reply['speaker']}] {reply['utterance']}"
                                    )

                            if human_utterance_count >= self.max_human_utterances:
                                break

        # çµ‚äº†æ™‚åˆ»
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        # æœ€çµ‚è©•ä¾¡
        final_metrics, final_stable, final_has_isolated = self.evaluate_relationships(
            logs
        )

        print(f"\nğŸ“ˆ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº†")
        print(f"  ç·äººé–“ç™ºè©±æ•°: {human_utterance_count}")
        print(f"  ãƒ­ãƒœãƒƒãƒˆä»‹å…¥å›æ•°: {intervention_count}")
        print(f"  æœ€çµ‚çŠ¶æ…‹: {'âœ… å®‰å®š' if final_stable else 'âŒ ä¸å®‰å®š'}")
        print(f"  æœ€çµ‚ä¸å®‰å®šä¸‰è§’å½¢æ•°: {final_metrics.get('unstable_triads', 0)}")
        print(f"  æœ€çµ‚ç–å¤–ãƒãƒ¼ãƒ‰: {final_metrics.get('isolated_nodes', [])}")
        print(f"  æ‰€è¦æ™‚é–“: {duration:.1f}ç§’")

        # çµ±è¨ˆã‚’è¿”ã™
        stats = {
            "episode_id": episode_id,
            "topic": topic,
            "topic_trigger": topic_trigger,
            "human_utterance_count": human_utterance_count,
            "robot_utterance_count": intervention_count,
            "final_stable": final_stable,
            "final_unstable_triads": final_metrics.get("unstable_triads", 0),
            "final_isolated_nodes": final_metrics.get("isolated_nodes", []),
            "duration_seconds": duration,
            "logs": logs,
            "robot_utterances": robot_utterances,
        }

        return stats

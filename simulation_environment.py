"""
ä¼šè©±ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒ
äººé–“LLM 3å + ãƒ­ãƒœãƒƒãƒˆä»‹å…¥ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
"""

import networkx as nx
from typing import List, Dict, Tuple, Optional
from datetime import datetime
import random
import config
from human_llm_simulator import HumanLLMSimulator
from intervention_planner import InterventionPlanner
from community_analyzer import CommunityAnalyzer
from azure_clients import get_azure_chat_completion_client, build_chat_completion_params
from log_filtering import filter_logs_by_human_count


class SimulationEnvironment:
    """ä¼šè©±ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒ"""

    def __init__(self):
        """åˆæœŸåŒ–"""
        self._CFG = config.get_config()

        # ãƒšãƒ«ã‚½ãƒŠè¨­å®šï¼ˆconfig.yamlã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
        personas_cfg = getattr(self._CFG.env, "personas", {})
        self.personas = list(personas_cfg.keys())
        self.persona_triggers = {
            name: info.get("triggers", []) if isinstance(info, dict) else []
            for name, info in personas_cfg.items()
        }

        # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
        sim_cfg = getattr(self._CFG, "simulation", None)
        self.max_human_utterances = getattr(sim_cfg, "max_human_utterances", 45)
        # é–¢ä¿‚æ€§æ¨å®šå‘¨æœŸ: å‚åŠ è€…æ•°ç™ºè©±ã”ã¨ï¼ˆãƒ­ãƒœãƒƒãƒˆç™ºè©±ã¯é™¤å¤–ï¼‰
        num_participants = getattr(self._CFG.participants, "num_participants", 3)
        self.stability_check_interval = num_participants
        self.consecutive_stable_threshold = getattr(
            sim_cfg, "consecutive_stable_threshold", 2
        )

        # äººé–“LLMã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼
        self.human_llm = HumanLLMSimulator(self.personas, self.persona_triggers)

        # CommunityAnalyzerã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä¿æŒï¼ˆEMAå±¥æ­´ã‚’ç¶­æŒã™ã‚‹ãŸã‚ï¼‰
        self.analyzer = CommunityAnalyzer()

        # è©±é¡Œç”Ÿæˆç”¨ã®æ—¢ä½¿ç”¨åœ°é›·ãƒªã‚¹ãƒˆ
        self.used_triggers = []

    def generate_topic(self) -> Tuple[str, Optional[str]]:
        """
        è©±é¡Œã‚’ç”Ÿæˆ

        Returns:
            (topic, topic_trigger): è©±é¡Œã¨ãƒˆãƒªã‚¬ãƒ¼ã¨ãªã£ãŸåœ°é›·
        """
        # å…¨åœ°é›·ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«1ã¤é¸æŠï¼ˆæ—¢ã«ä½¿ç”¨ã—ãŸåœ°é›·ã¯é™¤å¤–ï¼‰
        all_triggers = set()
        for triggers in self.persona_triggers.values():
            all_triggers.update(triggers)

        available_triggers = list(all_triggers - set(self.used_triggers))

        if not available_triggers:
            # å…¨ã¦ä½¿ã„åˆ‡ã£ãŸã‚‰ãƒªã‚»ãƒƒãƒˆ
            self.used_triggers = []
            available_triggers = list(all_triggers)

        if not available_triggers:
            return "è‡ªç”±ãªè©±é¡Œ", None

        selected_trigger = random.choice(available_triggers)
        self.used_triggers.append(selected_trigger)

        # Azure OpenAI ã§è©±é¡Œç”Ÿæˆ
        client, deployment = get_azure_chat_completion_client(
            self._CFG.llm, model_type="topic"
        )
        if not client or not deployment:
            return f"{selected_trigger}ã«ã¤ã„ã¦", selected_trigger

        # config.yamlã‹ã‚‰è©±é¡Œç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã¿
        topic_cfg = getattr(self._CFG, "topic_manager", None)
        if topic_cfg and hasattr(topic_cfg, "generation_prompt"):
            prompt_template = topic_cfg.generation_prompt
            # {trigger_examples}ã‚’å®Ÿéš›ã®ãƒˆãƒªã‚¬ãƒ¼ã§ç½®ãæ›ãˆ
            generation_prompt = prompt_template.replace(
                "{trigger_examples}", selected_trigger
            )
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            generation_prompt = f"""
ã‚ãªãŸã¯äººé–“{len(self.personas)}äººãŒè©±ã™ãŸã‚ã®ã€è©±é¡Œã‚’1ã¤ã ã‘ææ¡ˆã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

ä»¥ä¸‹ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«é–¢é€£ã™ã‚‹è©±é¡Œã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š
{selected_trigger}

è©±é¡Œã‚’1ãƒ•ãƒ¬ãƒ¼ã‚ºï¼ˆ3-10èªï¼‰ã§1ã¤ã ã‘ææ¡ˆã—ã¦ãã ã•ã„ã€‚
"""

        messages = [{"role": "user", "content": generation_prompt}]
        params = build_chat_completion_params(
            deployment, messages, self._CFG.llm, temperature=0.9
        )

        try:
            res = client.chat.completions.create(**params)
            topic = res.choices[0].message.content.strip()
            return topic, selected_trigger
        except Exception as e:
            print(f"âš ï¸ è©±é¡Œç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return f"{selected_trigger}ã«ã¤ã„ã¦", selected_trigger

    def evaluate_relationships(self, logs: List[Dict]) -> Tuple[Dict, bool, bool]:
        """
        é–¢ä¿‚æ€§ã‚’è©•ä¾¡

        Args:
            logs: ä¼šè©±ãƒ­ã‚°

        Returns:
            (metrics, is_stable, has_isolated): é–¢ä¿‚æ€§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€å®‰å®šåˆ¤å®šã€ç–å¤–ãƒãƒ¼ãƒ‰æœ‰ç„¡
        """
        # CommunityAnalyzerã‚’ä½¿ç”¨ã—ã¦é–¢ä¿‚æ€§ã‚’è©•ä¾¡ï¼ˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å†åˆ©ç”¨ï¼‰
        analyzer = self.analyzer

        # ç›´è¿‘ max_history_relation å€‹ã®äººé–“ç™ºè©± + ãã®é–“ã®ãƒ­ãƒœãƒƒãƒˆç™ºè©±ã‚’æŠ½å‡º
        # ãƒ­ãƒœãƒƒãƒˆç™ºè©±ã«å¯¾ã™ã‚‹äººé–“ã®åå¿œã‚’æ­£ã—ãç†è§£ã™ã‚‹ãŸã‚ã€ãƒ­ãƒœãƒƒãƒˆç™ºè©±ã‚‚å«ã‚ã‚‹
        max_history_relation = getattr(self._CFG.env, "max_history_relation", 3) or 3
        filtered_logs = filter_logs_by_human_count(
            logs, max_history_relation, exclude_robot=False
        )

        # äººé–“ç™ºè©±ã®ã¿ã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ã¦è©•ä¾¡å¯å¦ã‚’åˆ¤å®š
        human_only_logs = [log for log in filtered_logs if log.get("speaker") != "ãƒ­ãƒœãƒƒãƒˆ"]
        if len(human_only_logs) < 3:
            # äººé–“ç™ºè©±ãŒ3æœªæº€ã¯è©•ä¾¡ä¸å¯
            return {}, False, False

        # é–¢ä¿‚æ€§ã‚¹ã‚³ã‚¢ã‚’å–å¾—
        scores = analyzer.estimate_relation(filtered_logs)
        # GPTã®ç”Ÿã‚¹ã‚³ã‚¢ã‚’è¡¨ç¤º(1æ¡ä¸¸ã‚) ã¨EMAã‚’è¡¨ç¤ºï¼ˆæœ‰åŠ¹æ™‚ï¼‰- ã‚½ãƒ¼ãƒˆé †ã§è¡¨ç¤º
        try:
            gpt_scores = analyzer.last_gpt_scores
            ema_scores = analyzer.last_ema_scores
            if gpt_scores:
                # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º: A-B: GPT +0.7 -> EMA +0.6ï¼ˆã‚½ãƒ¼ãƒˆé †ï¼‰
                for k in sorted(gpt_scores.keys()):
                    a, b = k
                    g = gpt_scores.get(k)
                    e = ema_scores.get(k) if ema_scores else None
                    if getattr(analyzer, "use_ema", False) and e is not None:
                        print(f"  {a}-{b}: GPT {g:+.1f} -> EMA {e:+.1f}")
                    else:
                        print(f"  {a}-{b}: GPT {g:+.1f}")
        except Exception:
            pass

        # ã‚°ãƒ©ãƒ•æ§‹ç¯‰
        graph = nx.Graph()
        for (a, b), score in scores.items():
            graph.add_edge(a, b, score=score)

        # ä¸‰è§’å½¢ã®ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        triangle_scores = analyzer.analyze_triangles(graph)

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—
        metrics = {"edges": scores, "unstable_triads": 0, "isolated_nodes": []}

        # ä¸å®‰å®šä¸‰è§’å½¢ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        for triangle, (struct, avg_score) in triangle_scores.items():
            if struct in ("---", "++-", "+-+", "-++"):
                metrics["unstable_triads"] += 1

        # ç–å¤–ãƒãƒ¼ãƒ‰ã‚’æ¤œå‡ºï¼ˆå…¨ã¦ã®ã‚¨ãƒƒã‚¸ãŒè² ã®å€¤ï¼‰
        for node in self.personas:
            edges = []
            for other in self.personas:
                if other != node:
                    # ã‚¹ã‚³ã‚¢è¾æ›¸ã®ã‚­ãƒ¼ã¯å¸¸ã«ã‚½ãƒ¼ãƒˆæ¸ˆã¿ (a, b) where a < b
                    key = tuple(sorted([node, other]))
                    edges.append(scores.get(key, 0.0))
            # å…¨ã¦ã®ã‚¨ãƒƒã‚¸ãŒè² ã®å€¤ã®å ´åˆã®ã¿ç–å¤–ãƒãƒ¼ãƒ‰ã¨åˆ¤å®šï¼ˆ0.0ã¯å«ã¾ãªã„ï¼‰
            if edges and all(edge < 0.0 for edge in edges):
                metrics["isolated_nodes"].append(node)

        # å®‰å®šåˆ¤å®š: ä¸å®‰å®šä¸‰è§’å½¢æ•°ãŒ0 ã‹ã¤ ç–å¤–ãƒãƒ¼ãƒ‰ãŒå­˜åœ¨ã—ãªã„
        is_stable = (
            metrics["unstable_triads"] == 0 and len(metrics["isolated_nodes"]) == 0
        )
        has_isolated = len(metrics["isolated_nodes"]) > 0

        return metrics, is_stable, has_isolated

    def should_intervene(
        self, logs: List[Dict], metrics: Dict, scores: Dict = None, graph: nx.Graph = None
    ) -> Tuple[bool, Optional[Dict], Optional[str]]:
        """
        ä»‹å…¥åˆ¤å®š

        Args:
            logs: ä¼šè©±ãƒ­ã‚°
            metrics: é–¢ä¿‚æ€§ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            scores: é–¢ä¿‚æ€§ã‚¹ã‚³ã‚¢ï¼ˆevaluate_relationshipsã‹ã‚‰æ¸¡ã•ã‚Œã‚‹ï¼‰
            graph: é–¢ä¿‚æ€§ã‚°ãƒ©ãƒ•ï¼ˆevaluate_relationshipsã‹ã‚‰æ¸¡ã•ã‚Œã‚‹ï¼‰

        Returns:
            (should_intervene, plan, robot_utterance): ä»‹å…¥åˆ¤å®šã€ä»‹å…¥ãƒ—ãƒ©ãƒ³ã€ãƒ­ãƒœãƒƒãƒˆç™ºè©±
        """
        # ä¸å®‰å®šä¸‰è§’å½¢ã¾ãŸã¯ç–å¤–ãƒãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã«ä»‹å…¥
        unstable_triads = metrics.get("unstable_triads", 0)
        isolated_nodes = metrics.get("isolated_nodes", [])

        if unstable_triads == 0 and len(isolated_nodes) == 0:
            # å®‰å®šçŠ¶æ…‹ â†’ ä»‹å…¥ã—ãªã„
            return False, None, None

        # scoresã¨graphãŒæ¸¡ã•ã‚Œã¦ã„ãªã„å ´åˆã¯æ§‹ç¯‰ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
        if scores is None or graph is None:
            max_history_relation = getattr(self._CFG.env, "max_history_relation", 3) or 3
            filtered_logs = filter_logs_by_human_count(
                logs, max_history_relation, exclude_robot=True
            )
            scores = self.analyzer.estimate_relation(filtered_logs)
            graph = nx.Graph()
            for (a, b), score in scores.items():
                graph.add_edge(a, b, score=score)

        triangle_scores = self.analyzer.analyze_triangles(graph)

        # config.yamlã‹ã‚‰ä»‹å…¥è¨­å®šã‚’èª­ã¿è¾¼ã¿
        intervention_cfg = getattr(self._CFG, "intervention", None)
        isolation_threshold = (
            getattr(intervention_cfg, "isolation_threshold", 0.0)
            if intervention_cfg
            else 0.0
        )
        intervention_mode = (
            getattr(intervention_cfg, "mode", "proposal")
            if intervention_cfg
            else "proposal"
        )

        # InterventionPlannerã§ä»‹å…¥è¨ˆç”»
        planner = InterventionPlanner(
            graph=graph,
            triangle_scores=triangle_scores,
            isolation_threshold=isolation_threshold,
            mode=intervention_mode,
        )

        # config.yamlã‹ã‚‰ä»‹å…¥åˆ¤å®šç”¨ã®ä¼šè©±å±¥æ­´æ•°ã‚’èª­ã¿è¾¼ã¿
        # ç›´è¿‘ intervention_max_history å€‹ã®äººé–“ç™ºè©± + ãã®é–“ã®ãƒ­ãƒœãƒƒãƒˆç™ºè©±ã‚’å–å¾—
        intervention_max_history = (
            getattr(self._CFG.env, "intervention_max_history", 3) or 10
        )
        session_logs = filter_logs_by_human_count(
            logs, intervention_max_history, exclude_robot=False
        )
        plan = planner.plan_intervention(session_logs)

        if plan is None:
            return False, None, None

        # ãƒ­ãƒœãƒƒãƒˆç™ºè©±ã‚’ç”Ÿæˆ
        robot_utterance = planner.generate_robot_utterance(plan, session_logs)

        return True, plan, robot_utterance

    def run_episode(self, episode_id: int) -> Dict:
        """
        1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ

        Args:
            episode_id: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ID

        Returns:
            stats: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ±è¨ˆæƒ…å ±
        """
        print(f"\n{'='*80}")
        print(f"ï¿½ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ {episode_id}")
        print(f"{'='*80}")

        # EMAå±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆæ–°ã—ã„ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ï¼‰
        self.analyzer.reset_ema()

        # é–‹å§‹æ™‚åˆ»
        start_time = datetime.now()

        # è©±é¡Œã‚’ç”Ÿæˆ
        topic, topic_trigger = self.generate_topic()
        print(f"ï¿½ è©±é¡Œ: {topic}")
        if topic_trigger:
            print(f"  (ãƒˆãƒªã‚¬ãƒ¼: {topic_trigger})")

        # ä¼šè©±ãƒ­ã‚°
        logs = []
        robot_utterances = []

        # ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
        human_utterance_count = 0
        intervention_count = 0

        # çµ±è¨ˆç”¨å¤‰æ•°
        stability_checks = []
        isolation_checks = []
        edge_score_history = []
        positive_ratio_history = []
        intervention_improvements = []
        consecutive_stable_count = 0
        consecutive_unstable_count = 0
        consecutive_unstable_max = 0
        first_stable_utterance = None
        last_stable_state = None
        oscillation_count = 0
        early_termination = False

        print("\n")
        while human_utterance_count < self.max_human_utterances:
            # äººé–“ç™ºè©±ã‚’1ã¤ç”Ÿæˆ
            human_replies = self.human_llm.generate_human_reply(
                logs, topic=topic, topic_trigger=topic_trigger, num_speakers=1
            )

            if not human_replies:
                print("âš ï¸ äººé–“ç™ºè©±ç”Ÿæˆå¤±æ•—")
                break

            logs.extend(human_replies)
            human_utterance_count += 1

            # ç™ºè©±ã‚’è¡¨ç¤º
            for reply in human_replies:
                print(f"[{reply['speaker']}] {reply['utterance']}")

            # stability_check_interval ã”ã¨ã«é–¢ä¿‚æ€§è©•ä¾¡
            if human_utterance_count % self.stability_check_interval == 0:
                print(f"ğŸ“Š é–¢ä¿‚æ€§è©•ä¾¡ ({human_utterance_count}ç™ºè©±æ™‚ç‚¹)")
                
                # é–¢ä¿‚æ€§æ¨å®šç”¨ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—
                max_history_relation = getattr(self._CFG.env, "max_history_relation", 3) or 3
                relation_logs = filter_logs_by_human_count(logs, max_history_relation, exclude_robot=True)
                if relation_logs:
                    print(f"    â†’ {len(relation_logs)}ä»¶ã®ç™ºè©±ã‚’ä½¿ç”¨ã—ã¦é–¢ä¿‚æ€§ã‚’æ¨å®š")

                metrics, is_stable, has_isolated = self.evaluate_relationships(logs)
                
                # ç›´å‰ã®ãƒ­ãƒœãƒƒãƒˆä»‹å…¥ã®åŠ¹æœã‚’æ¸¬å®š
                if robot_utterances:
                    last_robot = robot_utterances[-1]
                    if "pre_score" in last_robot and last_robot["pre_score"] is not None:
                        target_edge = last_robot.get("target_edge")
                        pre_score = last_robot["pre_score"]
                        edges = metrics.get("edges", {})
                        post_score = edges.get(target_edge) or edges.get((target_edge[1], target_edge[0]))
                        if post_score is not None:
                            improvement = post_score - pre_score
                            intervention_improvements.append(improvement)
                            print(f"  ğŸ“ˆ ä»‹å…¥åŠ¹æœ: {target_edge[0]}-{target_edge[1]} = {pre_score:+.1f} â†’ {post_score:+.1f} (å¤‰åŒ–: {improvement:+.1f})")
                            # æ¸¬å®šæ¸ˆã¿ãªã®ã§ãƒ•ãƒ©ã‚°ã‚’å‰Šé™¤
                            del last_robot["pre_score"]
                            del last_robot["target_edge"]

                print(f"  ä¸å®‰å®šä¸‰è§’å½¢æ•°: {metrics.get('unstable_triads', 0)}")
                print(f"  ç–å¤–ãƒãƒ¼ãƒ‰: {metrics.get('isolated_nodes', [])}")
                print(f"  å®‰å®šçŠ¶æ…‹: {'âœ… ã¯ã„' if is_stable else 'âŒ ã„ã„ãˆ'}")

                # ã‚¨ãƒƒã‚¸ã‚¹ã‚³ã‚¢ã‚’è¡¨ç¤ºã¨è¨˜éŒ²
                edges = metrics.get("edges", {})
                if edges:
                    print(f"  é–¢ä¿‚æ€§ã‚¹ã‚³ã‚¢:")
                    for (a, b), score in sorted(edges.items()):
                        print(f"    {a}-{b}: {score:+.1f}")

                    # å…¨ã‚¨ãƒƒã‚¸å¹³å‡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
                    avg_edge_score = sum(edges.values()) / len(edges)
                    edge_score_history.append(avg_edge_score)

                    # æ­£ã‚¨ãƒƒã‚¸å‰²åˆã‚’è¨ˆç®—
                    positive_edges = sum(1 for score in edges.values() if score > 0)
                    positive_ratio = positive_edges / len(edges)
                    positive_ratio_history.append(positive_ratio)

                # å®‰å®šæ€§ã¨ç–å¤–ãƒãƒ¼ãƒ‰æœ‰ç„¡ã‚’è¨˜éŒ²
                stability_checks.append(is_stable)
                isolation_checks.append(has_isolated)

                # åˆå›å®‰å®šæ™‚ã®ç™ºè©±æ•°ã‚’è¨˜éŒ²
                if is_stable and first_stable_utterance is None:
                    first_stable_utterance = human_utterance_count
                    print(f"  ğŸ¯ åˆå›å®‰å®šé”æˆ: {human_utterance_count}ç™ºè©±")

                # å®‰å®šâ‡”ä¸å®‰å®šã®åˆ‡ã‚Šæ›¿ã‚ã‚Šã‚’æ¤œå‡º
                if last_stable_state is not None and last_stable_state != is_stable:
                    oscillation_count += 1
                last_stable_state = is_stable

                if is_stable:
                    consecutive_stable_count += 1
                    consecutive_unstable_count = 0
                    print(
                        f"  é€£ç¶šå®‰å®šå›æ•°: {consecutive_stable_count}/{self.consecutive_stable_threshold}\n"
                    )

                    if consecutive_stable_count >= self.consecutive_stable_threshold:
                        print(
                            f"\nğŸ‰ {self.consecutive_stable_threshold}å›é€£ç¶šã§å®‰å®š â†’ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº†"
                        )
                        early_termination = True
                        break
                else:
                    consecutive_stable_count = 0
                    consecutive_unstable_count += 1
                    # é€£ç¶šä¸å®‰å®šå›æ•°ã®æœ€å¤§å€¤ã‚’æ›´æ–°
                    consecutive_unstable_max = max(
                        consecutive_unstable_max, consecutive_unstable_count
                    )

                    # ä»‹å…¥åˆ¤å®šï¼ˆgraphã¨scoresã‚’æ¸¡ã—ã¦é‡è¤‡è¨ˆç®—ã‚’é˜²æ­¢ï¼‰
                    graph = nx.Graph()
                    for (a, b), score in edges.items():
                        graph.add_edge(a, b, score=score)
                    should_intervene, plan, robot_utterance = self.should_intervene(
                        logs, metrics, scores=edges, graph=graph
                    )

                    if should_intervene and robot_utterance:
                        intervention_count += 1
                        print(f"\nğŸ¤– ãƒ­ãƒœãƒƒãƒˆä»‹å…¥ ({intervention_count}å›ç›®)")
                        print(f"  ä»‹å…¥ã‚¿ã‚¤ãƒ—: {plan.get('type', 'ä¸æ˜')}")
                        print(f"  ç™ºè©±: {robot_utterance}")

                        # ä»‹å…¥å¯¾è±¡ã‚¨ãƒƒã‚¸ã®ä»‹å…¥å‰ã‚¹ã‚³ã‚¢ã‚’è¨˜éŒ²
                        target_edge = plan.get("edge")
                        pre_intervention_score = None
                        if target_edge and edges:
                            # ã‚¨ãƒƒã‚¸ã¯ (A, B) ã¾ãŸã¯ (B, A) ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ä¸¡æ–¹ãƒã‚§ãƒƒã‚¯
                            pre_intervention_score = edges.get(
                                target_edge
                            ) or edges.get((target_edge[1], target_edge[0]))
                            if pre_intervention_score is not None:
                                print(f"  ä»‹å…¥å¯¾è±¡ã‚¨ãƒƒã‚¸: {target_edge[0]}-{target_edge[1]} (ä»‹å…¥å‰: {pre_intervention_score:+.1f})")

                        robot_entry = {
                            "speaker": "ãƒ­ãƒœãƒƒãƒˆ",
                            "utterance": robot_utterance,
                            "plan": plan,
                            "pre_score": pre_intervention_score,  # æ¬¡ã®é–¢ä¿‚æ€§æ¨å®šæ™‚ã«ä½¿ç”¨
                            "target_edge": target_edge,
                        }
                        logs.append(robot_entry)
                        robot_utterances.append(robot_entry)

        # çµ‚äº†æ™‚åˆ»
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        # æœ€çµ‚è©•ä¾¡ï¼ˆæ—©æœŸçµ‚äº†ã§ãªã„å ´åˆã®ã¿ï¼‰
        if not early_termination:
            final_metrics, final_stable, final_has_isolated = self.evaluate_relationships(
                logs
            )
        else:
            # æ—©æœŸçµ‚äº†ã®å ´åˆã¯æœ€å¾Œã®è©•ä¾¡çµæœã‚’ä½¿ç”¨
            final_metrics = metrics
            final_stable = is_stable
            final_has_isolated = has_isolated

        print(f"\nğŸ“ˆ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº†")
        print(f"  ç·äººé–“ç™ºè©±æ•°: {human_utterance_count}")
        print(f"  ãƒ­ãƒœãƒƒãƒˆä»‹å…¥å›æ•°: {intervention_count}")
        print(
            f"  æ—©æœŸçµ‚äº†: {'âœ… ã¯ã„ (2é€£ç¶šå®‰å®š)' if early_termination else 'âŒ ã„ã„ãˆ'}"
        )
        print(f"  æœ€çµ‚çŠ¶æ…‹: {'âœ… å®‰å®š' if final_stable else 'âŒ ä¸å®‰å®š'}")
        print(f"  æœ€çµ‚ä¸å®‰å®šä¸‰è§’å½¢æ•°: {final_metrics.get('unstable_triads', 0)}")
        print(f"  æœ€çµ‚ç–å¤–ãƒãƒ¼ãƒ‰: {final_metrics.get('isolated_nodes', [])}")
        print(f"  æ‰€è¦æ™‚é–“: {duration:.1f}ç§’")

        # æ–°è¦æŒ‡æ¨™ã®è¨ˆç®—
        num_checks = len(stability_checks)
        stable_count_in_checks = sum(stability_checks)  # å®‰å®šè©•ä¾¡å›æ•°
        stability_rate = stable_count_in_checks / num_checks if num_checks > 0 else 0.0
        isolation_occurrence_rate = (
            sum(isolation_checks) / num_checks if num_checks > 0 else 0.0
        )
        avg_edge_score = (
            sum(edge_score_history) / len(edge_score_history)
            if edge_score_history
            else 0.0
        )
        avg_positive_ratio = (
            sum(positive_ratio_history) / len(positive_ratio_history)
            if positive_ratio_history
            else 0.0
        )
        intervention_success_rate = 0.0
        avg_improvement_per_intervention = 0.0
        if intervention_improvements:
            successful_interventions = sum(
                1 for imp in intervention_improvements if imp > 0
            )
            intervention_success_rate = successful_interventions / len(
                intervention_improvements
            )
            avg_improvement_per_intervention = sum(intervention_improvements) / len(
                intervention_improvements
            )
        intervention_frequency = (
            intervention_count / human_utterance_count
            if human_utterance_count > 0
            else 0.0
        )

        # æ–°è¦æŒ‡æ¨™: 1ä»‹å…¥ã‚ãŸã‚Šã®å®‰å®šç‡ã¨1å®‰å®šã‚ãŸã‚Šã®ãƒ­ãƒœãƒƒãƒˆä»‹å…¥å›æ•°
        stable_rate_per_intervention = (
            stable_count_in_checks / intervention_count
            if intervention_count > 0
            else 0.0
        )
        interventions_per_stable = (
            intervention_count / stable_count_in_checks
            if stable_count_in_checks > 0
            else 0.0
        )

        print(f"  å®‰å®šç‡: {stability_rate:.2%}")
        print(f"  ç–å¤–ç™ºç”Ÿç‡: {isolation_occurrence_rate:.2%}")
        if first_stable_utterance:
            print(f"  åˆå›å®‰å®šé”æˆ: {first_stable_utterance}ç™ºè©±")
        print(f"  åˆ‡ã‚Šæ›¿ã‚ã‚Šå›æ•°: {oscillation_count}å›")
        print(f"  é€£ç¶šä¸å®‰å®šæœ€å¤§: {consecutive_unstable_max}å›")

        # çµ±è¨ˆã‚’è¿”ã™
        stats = {
            "episode_id": episode_id,
            "topic": topic,
            "topic_trigger": topic_trigger,
            "human_utterance_count": human_utterance_count,
            "robot_utterance_count": intervention_count,
            "early_termination": early_termination,
            "final_stable": final_stable,
            "final_unstable_triads": final_metrics.get("unstable_triads", 0),
            "final_isolated_nodes": final_metrics.get("isolated_nodes", []),
            "duration_seconds": duration,
            "logs": logs,
            "robot_utterances": robot_utterances,
            # æ–°è¦æŒ‡æ¨™
            "stability_rate": stability_rate,
            "isolation_occurrence_rate": isolation_occurrence_rate,
            "first_stable_utterance": first_stable_utterance,
            "oscillation_count": oscillation_count,
            "consecutive_unstable_max": consecutive_unstable_max,
            "avg_edge_score": avg_edge_score,
            "avg_positive_ratio": avg_positive_ratio,
            "intervention_success_rate": intervention_success_rate,
            "avg_improvement_per_intervention": avg_improvement_per_intervention,
            "intervention_frequency": intervention_frequency,
            "stable_rate_per_intervention": stable_rate_per_intervention,
            "interventions_per_stable": interventions_per_stable,
        }

        return stats
